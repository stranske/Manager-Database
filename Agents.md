# ğŸ¤– Agents.md  
*A playbook for GitHubÂ Copilotâ€‘Chat / Codeâ€‘Assist (â€œCodexâ€) on this repo*  

> **Why this file?**  
> 1. The project has many moving parts (ETL, storage, UI, infra).  
> 2. You, dear human, said youâ€™re new to scraping & databases.  
> 3. Codex needs explicit, staged instructions so it knows when to charge ahead and when to raise its digital hand.

---

## 0. Ground rules for Codex

| Rule # | Guideline |
|-------|-----------|
| **R1** | **Stay inside the stage.** Work only on tasks defined for the current stage unless the user explicitly says otherwise. |
| **R2** | **Write, then explain.** For every code change you propose, add inline comments *and* a commitâ€‘message checklist. |
| **R3** | **One PR per atomic feature.** If a change affects >1 module, create separate branches / PRs. |
| **R4** | **When stuck, escalate.** Follow Â§7 *When to Ask for Outside Help*. |
| **R5** | **Keep GitHub tidy.** Always open/close Issues and update the Project board (Â§6) as you work. |

---

## 1. Repository map (autoâ€‘generated cheatâ€‘sheet)
.
â”œâ”€â”€ adapters/            # Data source modules (edgar, uk, canada, base)
â”œâ”€â”€ api/                 # FastAPI endpoints (chat)
â”œâ”€â”€ etl/                 # Prefect flows & helpers
â”‚Â Â  â”œâ”€â”€ edgar_flow.py
â”‚Â Â  â”œâ”€â”€ daily_diff_flow.py
â”‚Â Â  â””â”€â”€ summariser_flow.py
â”œâ”€â”€ ui/                  # Streamlit pages
â”‚Â Â  â”œâ”€â”€ dashboard.py
â”‚Â Â  â”œâ”€â”€ daily_report.py
â”‚Â Â  â”œâ”€â”€ search.py
â”‚Â Â  â””â”€â”€ upload.py
â”œâ”€â”€ tests/               # Pytest suite
â”œâ”€â”€ embeddings.py        # Embedding utilities
â”œâ”€â”€ diff_holdings.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ schema.sql
â”œâ”€â”€ README_bootstrap.md
â”œâ”€â”€ .pre-commit-config.yaml
â””â”€â”€ (this) Agents.md

*(update with `tree -L 2` occasionally)*

---

## 2. Prerequisites Codex assumes

1. **PythonÂ 3.12** available via `pyenv`.  
2. **Dockerâ€¯&â€¯ComposeÂ v2** installed.  
3. You have run `docker compose up -d` successfully at least once.  
4. Environment variables live in `.env` (never commit secrets).

---

## 3. Stage overview  
*(mirrors the phased roadmap in*Â `Managerâ€‘Intelâ€‘Platform.md`*)*

| Stage | Goal | Human inputs Codex needs |
|-------|------|--------------------------|
| **S0 â€“ Bootstrap** | Local stack running; costâ€‘log table created | A working Docker Desktop install |
| **S1 â€“ Proofâ€‘ofâ€‘Concept** | EDGAR adapter + holdings diff in **SQLite** | **CIK_LIST="0001791786,0001434997"** |
| **S2 â€“ Productionâ€¯ETL** | Prefect + Postgres + MinIO; multiâ€‘country adapters; tracked_call wrapper | API keys (SEC, Companiesâ€¯House, etc.) |
| **S3 â€“ Analyst Portal** | Streamlit dashboard skeleton | Basic brand colour / logo (optional) |
| **S4 â€“ AIâ€‘Assist (opt.)** | Vector embeddings + RAG chat | OpenAI key & model preferences |

Codex must not advance past a stage until all exitâ€‘criteria in Â§4 are met **and** an Issue titled `Promote to next stage` is closed.

---

## 4. Detailed task list per stage

### 4.1Â StageÂ 0Â â€”Â Bootstrap

1. **Generate** `docker-compose.yml` exactly as specified in *Managerâ€‘Intelâ€‘Platform.md*, but parameterise passwords via `.env`.  
2. **Create** `schema.sql` containing `api_usage` table.  
3. **Write** a GitHub Action:  
   * On push to `main` â†’ run `docker compose up -d && pytest -q`.  
4. **Open Issues automatically**:  
   * `#doc Improve README_bootstrap.md` (placeholder exists but has one line)
   * `#infra Add GitHub Action for CI`

**Exitâ€‘criteria**: `docker compose up` prints no errors; `api_usage` exists; CI badge shows green.

---

### 4.2Â StageÂ 1Â â€”Â Proofâ€‘ofâ€‘Concept

1. **Implement** `adapters/edgar.py` with three async coroutines:  
   ```python
   async def list_new_filings(since): ...
   async def download(filing): ...
   async def parse(raw): ...

2. Write a Prefect flow in etl/edgar_flow.py that:

Accepts CIK_LIST via envâ€‘var (defaults to Elliott & SIR).

Saves raw JSON in minio://filings/raw/.

Inserts parsed rows into SQLite (dev.db).

3. Add a tiny diff_holdings.py script:

python diff_holdings.py 0000320193 â†’ prints additions / exits.

4. Unit tests (Pytest) covering:

Happyâ€‘path parse of Appleâ€™s last 13F.

Fails gracefully on HTTPâ€¯429.

5. **Sanity check**: raise `UserWarning` if a managerâ€™s `filings.recent` array
   doesn't include any `13F-HR`â€”flagging the edgeâ€‘case where a future test CIK
   isnâ€™t an institutional filer.

Exitâ€‘criteria: diff_holdings.py works for both sample CIKs; tests pass.

4.3Â StageÂ 2Â â€”Â Productionâ€¯ETL
Migrate from SQLite to Postgres container.

Introduce tracked_call() wrapper around every HTTP request (log to api_usage).

Add UK & Canada adapters; common base class lives in adapters/base.py.

Refactor Prefect to parameterise jurisdiction.

Upgrade tests: nightly regression via pytest -m nightly.

Security:

Encrypt MinIO bucket (sse-s3).

Store AWS creds in GitHub Secrets.

Exitâ€‘criteria: 90% test coverage; monthly_usage materialised view returns rows.

### 4.3.1Â â¡ï¸Â **New subâ€‘stageÂ 3.1 â€“ Daily report GUI**
1. In Streamlit, add `/daily_report.py`
   * Layout: dateâ€‘picker (defaults to *yesterday*), two tabs
     * **Filings & Diffs** â€“ table of filings + coloured Î” arrows
     * **News Pulse** â€“ top 20 NLPâ€‘tagged headlines
   * Provide â€œDownload CSVâ€ button.
2. Prefect cron: regenerate yesterdayâ€™s diff by 08:00 local time; cache in
   Postgres for fast page loads.

**Exitâ€‘criteria:** page renders in <500â€¯ms on laptop; csv matches onâ€‘screen grid.

4.4Â StageÂ 3Â â€”Â Analyst Portal
Generate a Streamlit app skeleton (ui/).

Pages:

dashboard.py â€“ delta table + sparkline.

search.py â€“ FTS query box.

Auth: simple cookieâ€‘based stub (st_authenticator).

Dockerâ€‘compose override: expose Streamlit onâ€¯8501.

Exitâ€‘criteria: User can log in and see holdings diff & latest news.

4.5Â StageÂ 4Â â€”Â AIâ€‘Assist (optional)
Embed each new document with sentence-transformers/all-MiniLM-L6-v2, store in PGvector.

Add /chat endpoint (FastAPI) for RAG.

Summariser: Prefect task that posts a markdown summary to an internal Slack/webhook.

Exitâ€‘criteria: Chat endpoint returns coherent replies.

5. Coding patterns Codex must follow
Branch naming: stage{N}/featureâ€‘shortâ€‘desc (e.g.Â stage2/adapterâ€‘uk).

Commits: Conventionalâ€¯Commits (feat:, fix:, chore:â€¦).

Testing: Pytest; run docker compose exec etl pytest -q.

Linting: Ruff + Black; include pre-commit config.

6. GitHub hygiene workflow (automated by Codex)
Issues:

For every task bullet in Â§4, open a matching Issue if none exists.

Close Issues automatically via PR description (Closes #12).

Project board (ProjectsÂ âˆ):

Columns: Backlog â†’ InÂ Progress â†’ Review â†’ Done.


Move the card whenever pushing to a branch tagged stage*.

Milestones: Mirror the M1â€¦M6 table in Managerâ€‘Intelâ€‘Platform.md and keep dueâ€‘dates in sync (fetch via raw.githubusercontent.com).

Codex must run a â€œboardâ€‘syncâ€ routine at the end of each session:
gh project item-status --project "Managerâ€‘Intel" \
  --item "$ISSUE_ID" --status "In Progress"

7. When Codex should escalate / ask the human
| Situation                                 | Escalation text template                                               |
| ----------------------------------------- | ---------------------------------------------------------------------- |
| Missing credentials / API key             | â€œPlease add **XYZ\_API\_KEY** to repository secrets and ping me.â€      |
| Ambiguous business rule (e.g. diff logic) | â€œI found two equally valid interpretations of â€¦ Which one?â€            |
| External service down >2â€¯h                | â€œEndpoint *foo* has been 5xx since <timestamp>. Proceed to mock? Y/N.â€ |
| Unitâ€‘test design unclear                  | â€œProvide an example input/output pair for â€¦â€                           |


8. Quickâ€‘reference commands for the human
# bring everything up
docker compose up -d

# run Prefect flow locally
prefect flow-run run --name edgar-test

# open psql shell
docker exec -it db psql -U postgres


9. Further reading links
SEC EDGAR API docs

Companies House API swagger

Prefect 2.0 â€œflows & deploymentsâ€ guide

Streamlit authentication examples

(Codex: turn each into footnoteâ€‘style links in README when relevant.)

---

### ğŸ“‹â€¯How Codex will keep GitHub Issues & Projects upâ€‘toâ€‘date
Yesâ€”having Codex draft Issues/Projectâ€‘board cards is both **possible** and **strongly advisable**.  
The instructions in Â§6 tell it to:

1. Parse every unchecked box in Â§4 into a new Issue (if one doesnâ€™t exist).  
2. Autoâ€‘move the Issueâ€™s card across *Backlog â†’ InÂ Progress â†’ Done* as soon as it pushes code or opens/merges a PR.  
3. Regenerate milestone dueâ€‘dates from the roadmap table so â€œrealâ€ and â€œsourceâ€‘ofâ€‘truthâ€ never drift.

Tools Codex can call:

```bash
# create issue
gh issue create --title "Stage1: Edgar adapter" --body "...details..."

# add to project
gh project item-add --project "Managerâ€‘Intel" --issue <id>
These commands already work with GitHub CLI; VSÂ Codeâ€™s builtâ€‘in Copilot Chat has permission to invoke them if youâ€™re signedâ€‘in.

1ï¸âƒ£ Sample managers (CIKs lockedâ€‘in)

| Manager | Description | Confirmed CIK | Sources |
| ------- | ----------- | ------------- | ------- |
| Elliottâ€¯Investmentâ€¯Managementâ€¯L.P. | Global multiâ€‘strategy activist fund | 0001791786 | [sec.gov](https://www.sec.gov), [13f.info](https://13f.info) |
| SIRâ€¯Capitalâ€¯Managementâ€¯L.P.<br/><small>umbrella for â€œStandardâ€¯Investmentâ€¯Researchâ€ energy vehicles</small> | Oil, gas & newâ€‘energy hedge fund | 0001434997 (13F FileÂ No.â€¯028â€‘13426) | [research.secdatabase.com](https://research.secdatabase.com), [sec.gov](https://www.sec.gov) |

Small print: SIR files genuine 13Fs under the management entity above; their various fund SPVs only file FormÂ D. Using the managerâ€‘level CIK lets the 13F POC work without surprises.

<!-----------------  ğŸ”§  CONFIG / METRIC UPGRADE  ---------------->
### :construction_worker: Task â€” ensure ShortfallProb is always produced

1 Â· **parameters template**  
   * open `config/parameters_template.csv`  
   * append a line (or update if it exists)  
     ```
     risk_metrics,Return,Risk,ShortfallProb
     ```
   * propagate the same change to any YAML sample (`params_template.yml`).

2 Â· **CLI sanity-check** (`pa_core/config.py`)  
   * on load, assert `"ShortfallProb" in cfg.risk_metrics`;  
     if absent, raise `ConfigError("risk_metrics must include ShortfallProb")`.

3 Â· **Excel exporter** (`pa_core/reporting/excel.py`)  
   * before writing the *Summary* sheet:  
     ```python
     summary["ShortfallProb"] = summary.get("ShortfallProb", 0.0)
     ```
     so old output files never explode the viz.

4 Â· **Dashboard guard-rail** (`pa_core/viz/risk_return.py`)  
   * same one-liner:  
     ```python
     df = df.copy()
     df["ShortfallProb"] = df.get("ShortfallProb", 0.0)
     ```

5 Â· **Regression test** (`tests/test_outputs.py`)  
   ```python
   import pandas as pd, pathlib
   def test_shortfall_present():
       fn = pathlib.Path("Outputs.xlsx")
       assert fn.exists(), "Outputs.xlsx missing"
       cols = pd.read_excel(fn, sheet_name="Summary").columns
       assert "ShortfallProb" in cols

